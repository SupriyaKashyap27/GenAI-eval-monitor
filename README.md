# GenAI Usage & Evaluation Monitor (Open Source)

## ğŸš€ Overview
An open-source tool designed for SMBs (especially Legal Tech firms) using Azure OpenAI + OSS LLMs to track token usage, estimate GenAI costs, and perform post-hoc AI evaluations for hallucinations, PII leaks, and more.

## ğŸŒŸ Problem
SMBs adopting GenAI on Azure face the following challenges:
- No unified view of AOAI + OSS model usage
- No clear link between app/agent behavior and cost
- No built-in tools for post-hoc LLM output evaluation
- Limited capacity to manage MLOps or AI risk infrastructure

## âœ… Solution
This tool provides:
- Token + model usage tracking across AOAI and OSS models
- Cost estimation using configurable token price inputs
- AI Evals: post-hoc analysis for PII, hallucinations, toxicity
- Unified dashboard and Slack/email alerts
- Audit reports for compliance-readiness

## ğŸ’» Architecture
- Python-based middleware intercepts LLM API calls
- Token tracking using `tiktoken` and `tokenizers`
- Eval layer using Presidio, Detoxify, heuristics
- Streamlit dashboard + Prometheus/Grafana (optional)
- Dockerized for easy deployment

## ğŸ“¦ OSS Stack
- tiktoken, HuggingFace tokenizers
- Presidio, Detoxify, Ragas (optional)
- Streamlit or FastAPI
- SQLite/Postgres
- Docker, GitHub Actions

## ğŸ§ª Use Cases
1. Cost driver analysis and prompt optimization
2. Post-hoc evals for output safety and hallucinations
3. AI audit trail generation
4. Alerting for excessive cost or risk

## ğŸ” Privacy & Ethics
- Optional logging of inputs/outputs with redaction
- Configurable eval thresholds and model registry

## ğŸ§± Getting Started
1. Clone this repo
2. Configure AOAI token prices in `config.yaml`
3. Insert middleware into your appâ€™s LLM call flow
4. Launch dashboard via `streamlit run dashboard.py`

## ğŸ“„ License
MIT

## ğŸ‘¤ Maintainers
Built by Supriya Kashyap in collaboration with GPT-4 for AI PM portfolio development.
